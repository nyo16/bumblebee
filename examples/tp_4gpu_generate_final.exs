# 4-GPU Tensor Parallel Text Generation - FINAL VERSION WITH RoPE
#
# This demonstrates production-quality autoregressive generation:
# - Tensor parallelism across 4 GPUs
# - KV cache for O(n) generation complexity
# - PROPER embedding lookup (gather)
# - PROPER RMSNorm normalization (reduce)
# - PROPER softmax attention (reduce)
# - PROPER Rotary Position Embeddings (RoPE)
# - Mistral 7B model
#
# Usage:
#   LAYERS=2 mix run examples/tp_4gpu_generate_final.exs

Nx.default_backend(EXLA.Backend)

IO.puts("=" |> String.duplicate(70))
IO.puts("4-GPU TP Generation - FINAL VERSION WITH RoPE - Mistral 7B")
IO.puts("=" |> String.duplicate(70))

alias EXLA.MLIR.{Function, Value, Region}

# Configuration
tp_size = 4
max_new_tokens = 20
temperature = 1.0

# Model size - will be loaded from Mistral 7B
num_layers = String.to_integer(System.get_env("LAYERS", "2"))  # Use fewer layers for demo

IO.puts("\nConfiguration:")
IO.puts("  TP size: #{tp_size}")
IO.puts("  Max new tokens: #{max_new_tokens}")
IO.puts("  Temperature: #{temperature}")

# ----------------------------------------------------------
# Step 1: Load model and tokenizer
# ----------------------------------------------------------
IO.puts("\n" <> ("-" |> String.duplicate(70)))
IO.puts("Step 1: Loading model and tokenizer")
IO.puts("-" |> String.duplicate(70))

IO.puts("  Loading Mistral 7B...")
{:ok, %{params: params, spec: spec}} = Bumblebee.load_model({:hf, "mistralai/Mistral-7B-v0.1"})
{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "mistralai/Mistral-7B-v0.1"})

vocab_size = spec.vocab_size
hidden_size = spec.hidden_size
intermediate_size = spec.intermediate_size
num_heads = spec.num_attention_heads
num_kv_heads = spec.num_key_value_heads
head_dim = div(hidden_size, num_heads)
rms_norm_eps = spec.layer_norm_epsilon
rope_theta = spec.rotary_embedding_base || 10_000.0

# Tensor parallelism configuration
local_heads = div(num_heads, tp_size)
local_kv_heads = div(num_kv_heads, tp_size)
kv_head_repeat = div(local_heads, local_kv_heads)
local_q_size = local_heads * head_dim
local_kv_size = local_kv_heads * head_dim
local_intermediate = div(intermediate_size, tp_size)

IO.puts("  Model loaded!")
IO.puts("  Vocab size: #{vocab_size}")
IO.puts("  Hidden size: #{hidden_size}")
IO.puts("  Using #{num_layers} layers for generation")
IO.puts("  RMS norm epsilon: #{rms_norm_eps}")
IO.puts("  RoPE theta: #{rope_theta}")

# Precompute RoPE sin/cos embeddings
# RoPE formula: inv_freq = 1.0 / (theta^(2i/dim)) for i in 0..dim/2-1
compute_rope_embeddings = fn max_positions ->
  # Compute inverse frequencies
  half_dim = div(head_dim, 2)
  inv_freq = for i <- 0..(half_dim - 1) do
    1.0 / :math.pow(rope_theta, 2 * i / head_dim)
  end
  inv_freq_tensor = Nx.tensor(inv_freq, type: :f32)

  # Positions: [0, 1, 2, ..., max_positions-1]
  positions = Nx.iota({max_positions}, type: :f32)

  # Outer product: positions x inv_freq -> [max_positions, half_dim]
  freqs = Nx.outer(positions, inv_freq_tensor)

  # Compute cos/sin of frequencies
  cos_freqs = Nx.cos(freqs)  # [max_positions, half_dim]
  sin_freqs = Nx.sin(freqs)  # [max_positions, half_dim]

  # Standard RoPE: concatenate [cos_freqs, cos_freqs] to get [max_positions, head_dim]
  # The first half and second half have the same values
  cos_embed = Nx.concatenate([cos_freqs, cos_freqs], axis: 1)  # [max_positions, head_dim]
  sin_embed = Nx.concatenate([sin_freqs, sin_freqs], axis: 1)  # [max_positions, head_dim]

  {cos_embed, sin_embed}
end

# ----------------------------------------------------------
# Step 2: Extract and shard parameters
# ----------------------------------------------------------
IO.puts("\n" <> ("-" |> String.duplicate(70)))
IO.puts("Step 2: Extracting and sharding parameters")
IO.puts("-" |> String.duplicate(70))

param_data = params.data

# Extract global parameters (not sharded) - Mistral paths
embed_tokens = param_data["embedder.token_embedding"]["kernel"]
final_norm_weight = param_data["output_norm"]["weight"]
lm_head_kernel = param_data["language_modeling_head.output"]["kernel"]

# Extract and shard layer parameters
layer_params = for layer_idx <- 0..(num_layers - 1) do
  layer_prefix = "decoder.blocks.#{layer_idx}"

  # Norms (replicated) - Mistral uses "weight" not "scale"
  sa_norm = param_data["#{layer_prefix}.self_attention_norm"]["weight"]
  ffn_norm = param_data["#{layer_prefix}.output_norm"]["weight"]

  # Attention weights
  q_kernel = param_data["#{layer_prefix}.self_attention.query"]["kernel"]
  k_kernel = param_data["#{layer_prefix}.self_attention.key"]["kernel"]
  v_kernel = param_data["#{layer_prefix}.self_attention.value"]["kernel"]
  o_kernel = param_data["#{layer_prefix}.self_attention.output"]["kernel"]

  # Shard attention weights (column-parallel for Q/K/V, row-parallel for O)
  q_shards = for i <- 0..(tp_size - 1), do: Nx.slice(q_kernel, [0, i * local_q_size], [hidden_size, local_q_size])
  k_shards = for i <- 0..(tp_size - 1), do: Nx.slice(k_kernel, [0, i * local_kv_size], [hidden_size, local_kv_size])
  v_shards = for i <- 0..(tp_size - 1), do: Nx.slice(v_kernel, [0, i * local_kv_size], [hidden_size, local_kv_size])
  o_shards = for i <- 0..(tp_size - 1), do: Nx.slice(o_kernel, [i * local_q_size, 0], [local_q_size, hidden_size])

  # FFN weights
  gate_kernel = param_data["#{layer_prefix}.ffn.gate"]["kernel"]
  up_kernel = param_data["#{layer_prefix}.ffn.intermediate"]["kernel"]
  down_kernel = param_data["#{layer_prefix}.ffn.output"]["kernel"]

  # Shard FFN weights (column-parallel for gate/up, row-parallel for down)
  gate_shards = for i <- 0..(tp_size - 1), do: Nx.slice(gate_kernel, [0, i * local_intermediate], [hidden_size, local_intermediate])
  up_shards = for i <- 0..(tp_size - 1), do: Nx.slice(up_kernel, [0, i * local_intermediate], [hidden_size, local_intermediate])
  down_shards = for i <- 0..(tp_size - 1), do: Nx.slice(down_kernel, [i * local_intermediate, 0], [local_intermediate, hidden_size])

  %{
    sa_norm: sa_norm, ffn_norm: ffn_norm,
    q_shards: q_shards, k_shards: k_shards, v_shards: v_shards, o_shards: o_shards,
    gate_shards: gate_shards, up_shards: up_shards, down_shards: down_shards
  }
end

IO.puts("  Extracted #{num_layers} layer parameters")

# ----------------------------------------------------------
# Step 3: Build SPMD executables with KV cache
# ----------------------------------------------------------
IO.puts("\n" <> ("-" |> String.duplicate(70)))
IO.puts("Step 3: Building SPMD executables with proper ops")
IO.puts("-" |> String.duplicate(70))

# Maximum sequence length for KV cache (reserved for future optimization)
_max_seq_len = 512

# Prefill phase: Process prompt and initialize KV cache
IO.puts("  Building prefill SPMD (with proper gather, RMSNorm, softmax, RoPE)...")

build_prefill_spmd = fn batch_size, prompt_len ->
  input_ids_typespec = EXLA.Typespec.tensor({:s, 32}, {batch_size, prompt_len})
  embed_typespec = EXLA.Typespec.tensor({:f, 32}, {vocab_size, hidden_size})
  norm_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size})
  lm_head_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, vocab_size})

  # RoPE embeddings: [prompt_len, head_dim]
  rope_cos_typespec = EXLA.Typespec.tensor({:f, 32}, {prompt_len, head_dim})
  rope_sin_typespec = EXLA.Typespec.tensor({:f, 32}, {prompt_len, head_dim})

  q_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, local_q_size})
  k_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, local_kv_size})
  v_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, local_kv_size})
  o_typespec = EXLA.Typespec.tensor({:f, 32}, {local_q_size, hidden_size})
  gate_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, local_intermediate})
  up_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, local_intermediate})
  down_typespec = EXLA.Typespec.tensor({:f, 32}, {local_intermediate, hidden_size})

  layer_param_typespecs = List.duplicate([
    norm_typespec, norm_typespec,
    q_typespec, k_typespec, v_typespec, o_typespec,
    gate_typespec, up_typespec, down_typespec
  ], num_layers) |> List.flatten()

  input_typespecs = [input_ids_typespec, embed_typespec, norm_typespec, lm_head_typespec, rope_cos_typespec, rope_sin_typespec] ++ layer_param_typespecs

  # Outputs: logits + K/V caches for each layer
  output_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, vocab_size})
  k_cache_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, prompt_len, head_dim})
  v_cache_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, prompt_len, head_dim})

  # One K and V cache per layer
  cache_typespecs = List.duplicate([k_cache_typespec, v_cache_typespec], num_layers) |> List.flatten()
  output_typespecs = [output_typespec] ++ cache_typespecs

  replica_groups = [Enum.to_list(0..(tp_size - 1))]

  EXLA.SPMD.build(input_typespecs, output_typespecs, fn builder ->
    args = Function.get_arguments(builder)
    [input_ids, embed_w, final_norm_w, lm_head_w, rope_cos, rope_sin | layer_args] = args

    layer_weights = Enum.chunk_every(layer_args, 9)
    |> Enum.map(fn [sa_norm, ffn_norm, q, k, v, o, gate, up, down] ->
      %{sa_norm: sa_norm, ffn_norm: ffn_norm, q: q, k: k, v: v, o: o, gate: gate, up: up, down: down}
    end)

    hidden_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len, hidden_size})

    # RoPE application function
    # Formula: rotated = x * cos + rotate_half(x) * sin
    # Where rotate_half([x0, x1, x2, x3, ...]) = [-x1, x0, -x3, x2, ...]
    apply_rope = fn x, cos_embed, sin_embed, x_typespec ->
      # x shape: [batch, num_heads, seq_len, head_dim]
      # cos/sin shape: [seq_len, head_dim]

      # Broadcast cos/sin to match x shape
      {batch_local, num_heads_local, seq_len_local, _head_dim_local} = x_typespec.shape
      cos_4d_typespec = EXLA.Typespec.tensor({:f, 32}, {1, 1, seq_len_local, head_dim})
      sin_4d_typespec = EXLA.Typespec.tensor({:f, 32}, {1, 1, seq_len_local, head_dim})

      cos_4d = Value.reshape(cos_embed, cos_4d_typespec)
      sin_4d = Value.reshape(sin_embed, sin_4d_typespec)

      cos_broadcast = Value.broadcast_in_dim(cos_4d, [0, 1, 2, 3], x_typespec)
      sin_broadcast = Value.broadcast_in_dim(sin_4d, [0, 1, 2, 3], x_typespec)

      # Create rotate_half(x)
      # Split x into first half and second half along head_dim
      half_dim = div(head_dim, 2)
      first_half_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_local, num_heads_local, seq_len_local, half_dim})
      second_half_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_local, num_heads_local, seq_len_local, half_dim})

      # Slice first half: [0:batch, 0:heads, 0:seq, 0:half_dim]
      x_first = Value.slice(x, [0, 0, 0, 0], [batch_local, num_heads_local, seq_len_local, half_dim], [1, 1, 1, 1], first_half_typespec)
      # Slice second half: [0:batch, 0:heads, 0:seq, half_dim:head_dim]
      x_second = Value.slice(x, [0, 0, 0, half_dim], [batch_local, num_heads_local, seq_len_local, head_dim], [1, 1, 1, 1], second_half_typespec)

      # Negate second half
      neg_one = Value.constant(builder, [-1.0], EXLA.Typespec.tensor({:f, 32}, {}))
      neg_one_broadcast = Value.broadcast_in_dim(neg_one, [], second_half_typespec)
      x_second_neg = Value.multiply(x_second, neg_one_broadcast, second_half_typespec)

      # rotate_half = concat(-x_second, x_first)
      x_rotated = Value.concatenate([x_second_neg, x_first], 3, x_typespec)

      # Apply rotation: x * cos + rotate_half(x) * sin
      x_cos = Value.multiply(x, cos_broadcast, x_typespec)
      x_rot_sin = Value.multiply(x_rotated, sin_broadcast, x_typespec)
      Value.add(x_cos, x_rot_sin, x_typespec)
    end

    # PROPER EMBEDDING LOOKUP using gather
    # Gather signature: gather(source, indices, index_vector_dim, slice_sizes, offset_dims, collapsed_slice_dims, start_index_map, typespec)
    # For embedding lookup: source=[vocab_size, hidden_size], indices=[batch, seq_len]
    # We want output=[batch, seq_len, hidden_size]
    hidden_states = Value.gather(
      embed_w,                    # source: [vocab_size, hidden_size]
      input_ids,                  # indices: [batch, prompt_len]
      2,                          # index_vector_dim (outside indices dims, so indices are scalars)
      [1, hidden_size],          # slice_sizes: take [1, hidden_size] slice for each index
      [2],                        # offset_dims: hidden_size goes to output dim 2 (after batch, seq)
      [0],                        # collapsed_slice_dims: collapse vocab dim (dim 0 of slice)
      [0],                        # start_index_map: index maps to vocab dim (dim 0 of source)
      hidden_typespec
    )

    # PROPER RMSNorm implementation
    rms_norm = fn x, weight, typespec ->
      # RMSNorm: x * weight / sqrt(mean(x^2) + eps)

      # Step 1: x^2
      x_squared_typespec = typespec
      x_squared = Value.multiply(x, x, x_squared_typespec)

      # Step 2: Reduce sum over hidden dimension to get sum(x^2)
      # Need to create a reduction region
      scalar_typespec = EXLA.Typespec.tensor({:f, 32}, {})
      reduce_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len})

      {region, [lhs, rhs]} = Function.push_region(builder, [scalar_typespec, scalar_typespec])
      sum_result = Value.add(lhs, rhs, scalar_typespec)
      Value.return(builder, [sum_result])
      Function.pop_region(builder)

      # Initial value for sum
      zero = Value.constant(builder, [0.0], scalar_typespec)

      # Reduce over dimension 2 (hidden_size dimension)
      [sum_squared] = Value.reduce(region, [zero], [x_squared], [2], [reduce_typespec])

      # Step 3: mean = sum / hidden_size
      hidden_size_constant = Value.constant(builder, [hidden_size * 1.0], scalar_typespec)
      hidden_size_broadcast = Value.broadcast_in_dim(hidden_size_constant, [], reduce_typespec)
      mean_squared = Value.divide(sum_squared, hidden_size_broadcast, reduce_typespec)

      # Step 4: Add epsilon
      epsilon_constant = Value.constant(builder, [rms_norm_eps], scalar_typespec)
      epsilon_broadcast = Value.broadcast_in_dim(epsilon_constant, [], reduce_typespec)
      mean_squared_eps = Value.add(mean_squared, epsilon_broadcast, reduce_typespec)

      # Step 5: rsqrt = 1 / sqrt(mean_squared + eps)
      rsqrt = Value.rsqrt(mean_squared_eps, reduce_typespec)

      # Step 6: Broadcast rsqrt back to full shape
      rsqrt_3d_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len, 1})
      rsqrt_3d = Value.reshape(rsqrt, rsqrt_3d_typespec)
      rsqrt_broadcast = Value.broadcast_in_dim(rsqrt_3d, [0, 1, 2], typespec)

      # Step 7: x * rsqrt
      normalized = Value.multiply(x, rsqrt_broadcast, typespec)

      # Step 8: Multiply by weight
      weight_broadcast = Value.broadcast_in_dim(weight, [2], typespec)
      Value.multiply(normalized, weight_broadcast, typespec)
    end

    # PROPER SOFTMAX implementation
    softmax = fn scores, scores_typespec, seq_dim ->
      # Softmax: exp(x - max(x)) / sum(exp(x - max(x)))

      # Get shape info - underscore unused vars to avoid warnings
      {_batch_size, _local_kv_heads, _kv_head_repeat, _query_len, _key_len} = scores_typespec.shape

      # Step 1: Find max along seq_dim
      scalar_typespec = EXLA.Typespec.tensor({:f, 32}, {})
      reduce_shape = Tuple.delete_at(scores_typespec.shape, seq_dim)
      reduce_typespec = EXLA.Typespec.tensor({:f, 32}, reduce_shape)

      {region, [lhs, rhs]} = Function.push_region(builder, [scalar_typespec, scalar_typespec])
      max_result = Value.max(lhs, rhs, scalar_typespec)
      Value.return(builder, [max_result])
      Function.pop_region(builder)

      # Initial value: negative infinity
      neg_inf = Value.constant(builder, [-1.0e9], scalar_typespec)

      # Reduce to find max
      [max_scores] = Value.reduce(region, [neg_inf], [scores], [seq_dim], [reduce_typespec])

      # Step 2: Broadcast max back to original shape
      max_expanded_typespec = EXLA.Typespec.tensor({:f, 32}, Tuple.insert_at(reduce_shape, seq_dim, 1))
      max_expanded = Value.reshape(max_scores, max_expanded_typespec)
      max_broadcast = Value.broadcast_in_dim(max_expanded, [0, 1, 2, 3, 4], scores_typespec)

      # Step 3: Subtract max (for numerical stability)
      scores_shifted = Value.subtract(scores, max_broadcast, scores_typespec)

      # Step 4: Exp
      scores_exp = Value.exp(scores_shifted, scores_typespec)

      # Step 5: Sum exp scores
      {region, [lhs, rhs]} = Function.push_region(builder, [scalar_typespec, scalar_typespec])
      sum_result = Value.add(lhs, rhs, scalar_typespec)
      Value.return(builder, [sum_result])
      Function.pop_region(builder)

      zero = Value.constant(builder, [0.0], scalar_typespec)
      [sum_exp] = Value.reduce(region, [zero], [scores_exp], [seq_dim], [reduce_typespec])

      # Step 6: Broadcast sum back
      sum_expanded = Value.reshape(sum_exp, max_expanded_typespec)
      sum_broadcast = Value.broadcast_in_dim(sum_expanded, [0, 1, 2, 3, 4], scores_typespec)

      # Step 7: Divide to get softmax
      Value.divide(scores_exp, sum_broadcast, scores_typespec)
    end

    # Process layers and collect K/V caches
    {final_hidden, kv_caches} = Enum.reduce(layer_weights, {hidden_states, []}, fn weights, {hidden, caches} ->
      # Self-attention with cache output
      normed_for_attn = rms_norm.(hidden, weights.sa_norm, hidden_typespec)

      q_proj_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len, local_q_size})
      k_proj_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len, local_kv_size})
      v_proj_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len, local_kv_size})

      q = Value.dot_general(normed_for_attn, weights.q, {[2], [], [0], []}, :default, q_proj_typespec)
      k = Value.dot_general(normed_for_attn, weights.k, {[2], [], [0], []}, :default, k_proj_typespec)
      v = Value.dot_general(normed_for_attn, weights.v, {[2], [], [0], []}, :default, v_proj_typespec)

      # Reshape for multi-head attention
      q_reshaped = Value.reshape(q, EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len, local_heads, head_dim}))
      k_reshaped = Value.reshape(k, EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len, local_kv_heads, head_dim}))
      v_reshaped = Value.reshape(v, EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len, local_kv_heads, head_dim}))

      # Transpose to [batch, heads, seq_len, head_dim]
      q_transposed_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_heads, prompt_len, head_dim})
      k_transposed_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, prompt_len, head_dim})
      v_transposed_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, prompt_len, head_dim})

      q_transposed_raw = Value.transpose(q_reshaped, [0, 2, 1, 3], q_transposed_typespec)
      k_transposed_raw = Value.transpose(k_reshaped, [0, 2, 1, 3], k_transposed_typespec)
      v_transposed = Value.transpose(v_reshaped, [0, 2, 1, 3], v_transposed_typespec)

      # Apply RoPE to Q and K
      q_transposed = apply_rope.(q_transposed_raw, rope_cos, rope_sin, q_transposed_typespec)
      k_transposed = apply_rope.(k_transposed_raw, rope_cos, rope_sin, k_transposed_typespec)

      # Store K/V for cache (these will be output) - K already has RoPE applied
      k_cache = k_transposed
      v_cache = v_transposed

      # Grouped query attention
      k_for_attn = Value.transpose(k_transposed, [0, 1, 3, 2], EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, head_dim, prompt_len}))

      q_grouped = Value.reshape(q_transposed, EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, prompt_len, head_dim}))
      k_expanded = Value.reshape(k_for_attn, EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, 1, head_dim, prompt_len}))
      v_expanded = Value.reshape(v_transposed, EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, 1, prompt_len, head_dim}))

      k_broadcast = Value.broadcast_in_dim(k_expanded, [0, 1, 2, 3, 4], EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, head_dim, prompt_len}))
      v_broadcast = Value.broadcast_in_dim(v_expanded, [0, 1, 2, 3, 4], EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, prompt_len, head_dim}))

      scores_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, prompt_len, prompt_len})
      scores = Value.dot_general(q_grouped, k_broadcast, {[4], [0, 1, 2], [3], [0, 1, 2]}, :default, scores_typespec)

      scale_value = 1.0 / :math.sqrt(head_dim)
      scale_typespec = EXLA.Typespec.tensor({:f, 32}, {})
      scale_tensor = Value.constant(builder, [scale_value], scale_typespec)
      scale_broadcast = Value.broadcast_in_dim(scale_tensor, [], scores_typespec)
      scores_scaled = Value.multiply(scores, scale_broadcast, scores_typespec)

      # CAUSAL MASKING: Create lower triangular mask
      # row_indices >= col_indices means we can attend (lower triangular including diagonal)
      row_typespec = EXLA.Typespec.tensor({:s, 32}, {prompt_len, 1})
      col_typespec = EXLA.Typespec.tensor({:s, 32}, {1, prompt_len})
      row_indices = Value.iota(builder, 0, row_typespec)
      col_indices = Value.iota(builder, 1, col_typespec)

      # Broadcast to [prompt_len, prompt_len]
      mask_2d_typespec = EXLA.Typespec.tensor({:s, 32}, {prompt_len, prompt_len})
      row_broadcast = Value.broadcast_in_dim(row_indices, [0, 1], mask_2d_typespec)
      col_broadcast = Value.broadcast_in_dim(col_indices, [0, 1], mask_2d_typespec)

      # Create causal mask: 1 where row >= col, 0 otherwise
      causal_mask_int = Value.greater_equal(row_broadcast, col_broadcast, EXLA.Typespec.tensor({:pred, 8}, {prompt_len, prompt_len}))

      # Convert to float and create mask values: 0 for attend, -inf for don't attend
      neg_inf_scalar = Value.constant(builder, [-1.0e9], scale_typespec)
      zero_scalar = Value.constant(builder, [0.0], scale_typespec)

      mask_float_typespec = EXLA.Typespec.tensor({:f, 32}, {prompt_len, prompt_len})
      neg_inf_mask = Value.broadcast_in_dim(neg_inf_scalar, [], mask_float_typespec)
      zero_mask = Value.broadcast_in_dim(zero_scalar, [], mask_float_typespec)

      # Select: where mask is true (can attend), use 0; else use -inf
      causal_mask_2d = Value.select(causal_mask_int, zero_mask, neg_inf_mask, mask_float_typespec)

      # Broadcast mask to full attention shape [batch, heads, kv_repeat, prompt_len, prompt_len]
      mask_5d_typespec = EXLA.Typespec.tensor({:f, 32}, {1, 1, 1, prompt_len, prompt_len})
      causal_mask_5d = Value.reshape(causal_mask_2d, mask_5d_typespec)
      causal_mask_broadcast = Value.broadcast_in_dim(causal_mask_5d, [0, 1, 2, 3, 4], scores_typespec)

      # Apply mask to scores
      scores_masked = Value.add(scores_scaled, causal_mask_broadcast, scores_typespec)

      # Apply PROPER softmax
      attention_weights = softmax.(scores_masked, scores_typespec, 4)

      attn_output_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, prompt_len, head_dim})
      attn_output = Value.dot_general(attention_weights, v_broadcast, {[4], [0, 1, 2], [3], [0, 1, 2]}, :default, attn_output_typespec)

      attn_merged = Value.reshape(attn_output, EXLA.Typespec.tensor({:f, 32}, {batch_size, local_heads, prompt_len, head_dim}))
      attn_transposed = Value.transpose(attn_merged, [0, 2, 1, 3], EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len, local_heads, head_dim}))
      attn_flat = Value.reshape(attn_transposed, EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len, local_q_size}))

      attn_partial = Value.dot_general(attn_flat, weights.o, {[2], [], [0], []}, :default, hidden_typespec)
      attn_result = Value.all_reduce(attn_partial, :sum, replica_groups, hidden_typespec)

      after_attn = Value.add(hidden, attn_result, hidden_typespec)

      # FFN
      normed_for_ffn = rms_norm.(after_attn, weights.ffn_norm, hidden_typespec)

      intermediate_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, prompt_len, local_intermediate})

      gate_out = Value.dot_general(normed_for_ffn, weights.gate, {[2], [], [0], []}, :default, intermediate_typespec)
      up_out = Value.dot_general(normed_for_ffn, weights.up, {[2], [], [0], []}, :default, intermediate_typespec)

      gate_sigmoid = Value.sigmoid(gate_out, intermediate_typespec)
      gate_silu = Value.multiply(gate_out, gate_sigmoid, intermediate_typespec)
      combined = Value.multiply(gate_silu, up_out, intermediate_typespec)

      ffn_partial = Value.dot_general(combined, weights.down, {[2], [], [0], []}, :default, hidden_typespec)
      ffn_result = Value.all_reduce(ffn_partial, :sum, replica_groups, hidden_typespec)

      layer_output = Value.add(after_attn, ffn_result, hidden_typespec)

      # Accumulate K/V caches for this layer
      {layer_output, caches ++ [k_cache, v_cache]}
    end)

    # Final norm + LM head (last position only)
    normed_output = rms_norm.(final_hidden, final_norm_w, hidden_typespec)

    last_hidden_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, hidden_size})
    last_hidden = Value.slice(normed_output, [0, prompt_len - 1, 0], [batch_size, prompt_len, hidden_size], [1, 1, 1], last_hidden_typespec)
    last_hidden_2d = Value.reshape(last_hidden, EXLA.Typespec.tensor({:f, 32}, {batch_size, hidden_size}))

    logits = Value.dot_general(last_hidden_2d, lm_head_w, {[1], [], [0], []}, :default, output_typespec)

    # Return logits + all K/V caches
    [logits] ++ kv_caches
  end, num_replicas: tp_size, client: :cuda)
end

IO.puts("  Prefill SPMD builder created!")

# Decode phase: Process single token with existing KV cache
IO.puts("  Building decode SPMD builder...")

build_decode_spmd = fn batch_size, cache_len ->
  # New sequence length after adding one token
  new_seq_len = cache_len + 1

  # Input: single token
  input_ids_typespec = EXLA.Typespec.tensor({:s, 32}, {batch_size, 1})
  embed_typespec = EXLA.Typespec.tensor({:f, 32}, {vocab_size, hidden_size})
  norm_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size})
  lm_head_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, vocab_size})

  # RoPE embeddings for the single new position: [1, head_dim]
  rope_cos_typespec = EXLA.Typespec.tensor({:f, 32}, {1, head_dim})
  rope_sin_typespec = EXLA.Typespec.tensor({:f, 32}, {1, head_dim})

  q_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, local_q_size})
  k_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, local_kv_size})
  v_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, local_kv_size})
  o_typespec = EXLA.Typespec.tensor({:f, 32}, {local_q_size, hidden_size})
  gate_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, local_intermediate})
  up_typespec = EXLA.Typespec.tensor({:f, 32}, {hidden_size, local_intermediate})
  down_typespec = EXLA.Typespec.tensor({:f, 32}, {local_intermediate, hidden_size})

  layer_param_typespecs = List.duplicate([
    norm_typespec, norm_typespec,
    q_typespec, k_typespec, v_typespec, o_typespec,
    gate_typespec, up_typespec, down_typespec
  ], num_layers) |> List.flatten()

  # Input K/V caches (previous sequence)
  k_cache_in_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, cache_len, head_dim})
  v_cache_in_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, cache_len, head_dim})
  cache_in_typespecs = List.duplicate([k_cache_in_typespec, v_cache_in_typespec], num_layers) |> List.flatten()

  input_typespecs = [input_ids_typespec, embed_typespec, norm_typespec, lm_head_typespec, rope_cos_typespec, rope_sin_typespec] ++ layer_param_typespecs ++ cache_in_typespecs

  # Outputs: logits + updated K/V caches
  output_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, vocab_size})
  k_cache_out_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, new_seq_len, head_dim})
  v_cache_out_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, new_seq_len, head_dim})
  cache_out_typespecs = List.duplicate([k_cache_out_typespec, v_cache_out_typespec], num_layers) |> List.flatten()
  output_typespecs = [output_typespec] ++ cache_out_typespecs

  replica_groups = [Enum.to_list(0..(tp_size - 1))]

  EXLA.SPMD.build(input_typespecs, output_typespecs, fn builder ->
    args = Function.get_arguments(builder)
    [input_ids, embed_w, final_norm_w, lm_head_w, rope_cos, rope_sin | rest_args] = args

    # Split into layer params (9 per layer) and caches (2 per layer)
    num_param_args = num_layers * 9
    {layer_param_args, cache_args} = Enum.split(rest_args, num_param_args)

    # Extract layer weights
    layer_weights = Enum.chunk_every(layer_param_args, 9)
    |> Enum.map(fn [sa_norm, ffn_norm, q, k, v, o, gate, up, down] ->
      %{sa_norm: sa_norm, ffn_norm: ffn_norm, q: q, k: k, v: v, o: o, gate: gate, up: up, down: down}
    end)

    # Extract K/V caches (2 per layer)
    cache_pairs = Enum.chunk_every(cache_args, 2)

    # Combine weights and caches
    layer_weights_and_caches = Enum.zip(layer_weights, cache_pairs)
    |> Enum.map(fn {weights, [k_cache_in, v_cache_in]} ->
      {weights, k_cache_in, v_cache_in}
    end)

    hidden_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, hidden_size})

    # RoPE application function for decode (single position)
    apply_rope_decode = fn x, cos_embed, sin_embed, x_typespec ->
      # x shape: [batch, num_heads, 1, head_dim]
      # cos/sin shape: [1, head_dim]

      {batch_local, num_heads_local, seq_len_local, _head_dim_local} = x_typespec.shape
      cos_4d_typespec = EXLA.Typespec.tensor({:f, 32}, {1, 1, 1, head_dim})
      sin_4d_typespec = EXLA.Typespec.tensor({:f, 32}, {1, 1, 1, head_dim})

      cos_4d = Value.reshape(cos_embed, cos_4d_typespec)
      sin_4d = Value.reshape(sin_embed, sin_4d_typespec)

      cos_broadcast = Value.broadcast_in_dim(cos_4d, [0, 1, 2, 3], x_typespec)
      sin_broadcast = Value.broadcast_in_dim(sin_4d, [0, 1, 2, 3], x_typespec)

      # Create rotate_half(x)
      half_dim = div(head_dim, 2)
      first_half_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_local, num_heads_local, seq_len_local, half_dim})
      second_half_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_local, num_heads_local, seq_len_local, half_dim})

      # Slice first half: [0:batch, 0:heads, 0:seq, 0:half_dim]
      x_first = Value.slice(x, [0, 0, 0, 0], [batch_local, num_heads_local, seq_len_local, half_dim], [1, 1, 1, 1], first_half_typespec)
      # Slice second half: [0:batch, 0:heads, 0:seq, half_dim:head_dim]
      x_second = Value.slice(x, [0, 0, 0, half_dim], [batch_local, num_heads_local, seq_len_local, head_dim], [1, 1, 1, 1], second_half_typespec)

      neg_one = Value.constant(builder, [-1.0], EXLA.Typespec.tensor({:f, 32}, {}))
      neg_one_broadcast = Value.broadcast_in_dim(neg_one, [], second_half_typespec)
      x_second_neg = Value.multiply(x_second, neg_one_broadcast, second_half_typespec)

      x_rotated = Value.concatenate([x_second_neg, x_first], 3, x_typespec)

      x_cos = Value.multiply(x, cos_broadcast, x_typespec)
      x_rot_sin = Value.multiply(x_rotated, sin_broadcast, x_typespec)
      Value.add(x_cos, x_rot_sin, x_typespec)
    end

    # PROPER EMBEDDING LOOKUP using gather (for single token)
    hidden_states = Value.gather(
      embed_w,
      input_ids,
      2,
      [1, hidden_size],
      [2],
      [0],
      [0],
      hidden_typespec
    )

    # PROPER RMSNorm implementation (for decode, seq_len=1)
    rms_norm = fn x, weight, typespec ->
      scalar_typespec = EXLA.Typespec.tensor({:f, 32}, {})
      reduce_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, 1})

      x_squared = Value.multiply(x, x, typespec)

      {region, [lhs, rhs]} = Function.push_region(builder, [scalar_typespec, scalar_typespec])
      sum_result = Value.add(lhs, rhs, scalar_typespec)
      Value.return(builder, [sum_result])
      Function.pop_region(builder)

      zero = Value.constant(builder, [0.0], scalar_typespec)
      [sum_squared] = Value.reduce(region, [zero], [x_squared], [2], [reduce_typespec])

      hidden_size_constant = Value.constant(builder, [hidden_size * 1.0], scalar_typespec)
      hidden_size_broadcast = Value.broadcast_in_dim(hidden_size_constant, [], reduce_typespec)
      mean_squared = Value.divide(sum_squared, hidden_size_broadcast, reduce_typespec)

      epsilon_constant = Value.constant(builder, [rms_norm_eps], scalar_typespec)
      epsilon_broadcast = Value.broadcast_in_dim(epsilon_constant, [], reduce_typespec)
      mean_squared_eps = Value.add(mean_squared, epsilon_broadcast, reduce_typespec)

      rsqrt = Value.rsqrt(mean_squared_eps, reduce_typespec)

      rsqrt_3d_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, 1})
      rsqrt_3d = Value.reshape(rsqrt, rsqrt_3d_typespec)
      rsqrt_broadcast = Value.broadcast_in_dim(rsqrt_3d, [0, 1, 2], typespec)

      normalized = Value.multiply(x, rsqrt_broadcast, typespec)
      weight_broadcast = Value.broadcast_in_dim(weight, [2], typespec)
      Value.multiply(normalized, weight_broadcast, typespec)
    end

    # Process layers with cache
    {final_hidden, updated_caches} = Enum.reduce(layer_weights_and_caches, {hidden_states, []}, fn {weights, k_cache_in, v_cache_in}, {hidden, acc_caches} ->
      normed_for_attn = rms_norm.(hidden, weights.sa_norm, hidden_typespec)

      q_proj_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, local_q_size})
      k_proj_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, local_kv_size})
      v_proj_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, local_kv_size})

      q = Value.dot_general(normed_for_attn, weights.q, {[2], [], [0], []}, :default, q_proj_typespec)
      k_new = Value.dot_general(normed_for_attn, weights.k, {[2], [], [0], []}, :default, k_proj_typespec)
      v_new = Value.dot_general(normed_for_attn, weights.v, {[2], [], [0], []}, :default, v_proj_typespec)

      # Reshape new K/V
      k_new_reshaped = Value.reshape(k_new, EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, local_kv_heads, head_dim}))
      v_new_reshaped = Value.reshape(v_new, EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, local_kv_heads, head_dim}))

      k_new_transposed_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, 1, head_dim})
      k_new_transposed_raw = Value.transpose(k_new_reshaped, [0, 2, 1, 3], k_new_transposed_typespec)
      v_new_transposed = Value.transpose(v_new_reshaped, [0, 2, 1, 3], EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, 1, head_dim}))

      # Apply RoPE to new K (the current position)
      k_new_transposed = apply_rope_decode.(k_new_transposed_raw, rope_cos, rope_sin, k_new_transposed_typespec)

      # Concatenate with cache (cached K's already have RoPE applied)
      k_full = Value.concatenate([k_cache_in, k_new_transposed], 2, k_cache_out_typespec)
      v_full = Value.concatenate([v_cache_in, v_new_transposed], 2, v_cache_out_typespec)

      # Reshape Q and apply RoPE
      q_reshaped = Value.reshape(q, EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, local_heads, head_dim}))
      q_transposed_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_heads, 1, head_dim})
      q_transposed_raw = Value.transpose(q_reshaped, [0, 2, 1, 3], q_transposed_typespec)
      q_transposed = apply_rope_decode.(q_transposed_raw, rope_cos, rope_sin, q_transposed_typespec)

      # Grouped query attention
      k_for_attn = Value.transpose(k_full, [0, 1, 3, 2], EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, head_dim, new_seq_len}))

      q_grouped = Value.reshape(q_transposed, EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, 1, head_dim}))
      k_expanded = Value.reshape(k_for_attn, EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, 1, head_dim, new_seq_len}))
      v_expanded = Value.reshape(v_full, EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, 1, new_seq_len, head_dim}))

      k_broadcast = Value.broadcast_in_dim(k_expanded, [0, 1, 2, 3, 4], EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, head_dim, new_seq_len}))
      v_broadcast = Value.broadcast_in_dim(v_expanded, [0, 1, 2, 3, 4], EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, new_seq_len, head_dim}))

      scores_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, 1, new_seq_len})
      scores = Value.dot_general(q_grouped, k_broadcast, {[4], [0, 1, 2], [3], [0, 1, 2]}, :default, scores_typespec)

      scale_value = 1.0 / :math.sqrt(head_dim)
      scale_typespec = EXLA.Typespec.tensor({:f, 32}, {})
      scale_tensor = Value.constant(builder, [scale_value], scale_typespec)
      scale_broadcast = Value.broadcast_in_dim(scale_tensor, [], scores_typespec)
      scores_scaled = Value.multiply(scores, scale_broadcast, scores_typespec)

      # PROPER SOFTMAX for decode phase
      scalar_typespec = EXLA.Typespec.tensor({:f, 32}, {})
      reduce_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, 1})

      {region, [lhs, rhs]} = Function.push_region(builder, [scalar_typespec, scalar_typespec])
      max_result = Value.max(lhs, rhs, scalar_typespec)
      Value.return(builder, [max_result])
      Function.pop_region(builder)

      neg_inf = Value.constant(builder, [-1.0e9], scalar_typespec)
      [max_scores] = Value.reduce(region, [neg_inf], [scores_scaled], [4], [reduce_typespec])

      max_expanded = Value.reshape(max_scores, EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, 1, 1}))
      max_broadcast = Value.broadcast_in_dim(max_expanded, [0, 1, 2, 3, 4], scores_typespec)
      scores_shifted = Value.subtract(scores_scaled, max_broadcast, scores_typespec)
      scores_exp = Value.exp(scores_shifted, scores_typespec)

      {region, [lhs, rhs]} = Function.push_region(builder, [scalar_typespec, scalar_typespec])
      sum_result = Value.add(lhs, rhs, scalar_typespec)
      Value.return(builder, [sum_result])
      Function.pop_region(builder)

      zero = Value.constant(builder, [0.0], scalar_typespec)
      [sum_exp] = Value.reduce(region, [zero], [scores_exp], [4], [reduce_typespec])

      sum_expanded = Value.reshape(sum_exp, EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, 1, 1}))
      sum_broadcast = Value.broadcast_in_dim(sum_expanded, [0, 1, 2, 3, 4], scores_typespec)
      attention_weights = Value.divide(scores_exp, sum_broadcast, scores_typespec)

      attn_output_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, local_kv_heads, kv_head_repeat, 1, head_dim})
      attn_output = Value.dot_general(attention_weights, v_broadcast, {[4], [0, 1, 2], [3], [0, 1, 2]}, :default, attn_output_typespec)

      attn_merged = Value.reshape(attn_output, EXLA.Typespec.tensor({:f, 32}, {batch_size, local_heads, 1, head_dim}))
      attn_transposed = Value.transpose(attn_merged, [0, 2, 1, 3], EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, local_heads, head_dim}))
      attn_flat = Value.reshape(attn_transposed, EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, local_q_size}))

      attn_partial = Value.dot_general(attn_flat, weights.o, {[2], [], [0], []}, :default, hidden_typespec)
      attn_result = Value.all_reduce(attn_partial, :sum, replica_groups, hidden_typespec)

      after_attn = Value.add(hidden, attn_result, hidden_typespec)

      # FFN
      normed_for_ffn = rms_norm.(after_attn, weights.ffn_norm, hidden_typespec)

      intermediate_typespec = EXLA.Typespec.tensor({:f, 32}, {batch_size, 1, local_intermediate})

      gate_out = Value.dot_general(normed_for_ffn, weights.gate, {[2], [], [0], []}, :default, intermediate_typespec)
      up_out = Value.dot_general(normed_for_ffn, weights.up, {[2], [], [0], []}, :default, intermediate_typespec)

      gate_sigmoid = Value.sigmoid(gate_out, intermediate_typespec)
      gate_silu = Value.multiply(gate_out, gate_sigmoid, intermediate_typespec)
      combined = Value.multiply(gate_silu, up_out, intermediate_typespec)

      ffn_partial = Value.dot_general(combined, weights.down, {[2], [], [0], []}, :default, hidden_typespec)
      ffn_result = Value.all_reduce(ffn_partial, :sum, replica_groups, hidden_typespec)

      layer_output = Value.add(after_attn, ffn_result, hidden_typespec)

      {layer_output, acc_caches ++ [k_full, v_full]}
    end)

    # Final norm + LM head
    normed_output = rms_norm.(final_hidden, final_norm_w, hidden_typespec)
    last_hidden_2d = Value.reshape(normed_output, EXLA.Typespec.tensor({:f, 32}, {batch_size, hidden_size}))
    logits = Value.dot_general(last_hidden_2d, lm_head_w, {[1], [], [0], []}, :default, output_typespec)

    [logits] ++ updated_caches
  end, num_replicas: tp_size, client: :cuda)
end

IO.puts("  Decode SPMD builder created!")
IO.puts("  Note: This will take longer to compile due to proper operations")

# ----------------------------------------------------------
# Step 4: Tokenize prompt
# ----------------------------------------------------------
IO.puts("\n" <> ("-" |> String.duplicate(70)))
IO.puts("Step 4: Tokenizing prompt")
IO.puts("-" |> String.duplicate(70))

prompt = "The meaning of life is"
IO.puts("  Prompt: \"#{prompt}\"")

tokenized = Bumblebee.apply_tokenizer(tokenizer, prompt)
input_ids = tokenized["input_ids"] |> Nx.as_type(:s32)
prompt_length = Nx.axis_size(input_ids, 1)

IO.puts("  Token IDs: #{inspect(Nx.to_flat_list(input_ids))}")
IO.puts("  Prompt length: #{prompt_length} tokens")

# ----------------------------------------------------------
# Step 5: Test prefill phase
# ----------------------------------------------------------
IO.puts("\n" <> ("-" |> String.duplicate(70)))
IO.puts("Step 5: Testing prefill phase")
IO.puts("-" |> String.duplicate(70))

IO.puts("  Building prefill SPMD for prompt_len=#{prompt_length}...")
IO.puts("  (This may take a while due to proper gather/reduce/softmax...)")
prefill_spmd = build_prefill_spmd.(1, prompt_length)

# Prepare replica inputs
prepare_prefill_inputs = fn input_ids, rope_cos, rope_sin ->
  for gpu <- 0..(tp_size - 1) do
    layer_params_for_gpu = Enum.flat_map(layer_params, fn layer ->
      [
        layer.sa_norm, layer.ffn_norm,
        Enum.at(layer.q_shards, gpu), Enum.at(layer.k_shards, gpu),
        Enum.at(layer.v_shards, gpu), Enum.at(layer.o_shards, gpu),
        Enum.at(layer.gate_shards, gpu), Enum.at(layer.up_shards, gpu),
        Enum.at(layer.down_shards, gpu)
      ]
    end)

    [input_ids, embed_tokens, final_norm_weight, lm_head_kernel, rope_cos, rope_sin] ++ layer_params_for_gpu
  end
end

IO.puts("  Running prefill on #{tp_size} GPUs...")
{rope_cos_prefill, rope_sin_prefill} = compute_rope_embeddings.(prompt_length)
replica_inputs = prepare_prefill_inputs.(input_ids, rope_cos_prefill, rope_sin_prefill)

{time_us, results} = :timer.tc(fn ->
  EXLA.SPMD.run(prefill_spmd, replica_inputs)
end)

IO.puts("  Prefill completed in #{Float.round(time_us / 1000, 2)} ms")

# Extract results
[[logits | kv_caches] | _] = results

IO.puts("\n  Output shapes:")
IO.puts("    Logits: #{inspect(Nx.shape(logits))}")
IO.puts("    Number of K/V cache pairs: #{div(length(kv_caches), 2)}")
IO.puts("    K cache shape (per layer): #{inspect(Nx.shape(hd(kv_caches)))}")

# Sample first token
next_token = Nx.argmax(logits, axis: 1) |> Nx.to_flat_list() |> hd()
IO.puts("\n  First generated token: #{next_token}")
IO.puts("  Decoded: \"#{Bumblebee.Tokenizer.decode(tokenizer, [next_token])}\"")

# ----------------------------------------------------------
# Step 6: Autoregressive generation with KV cache
# ----------------------------------------------------------
IO.puts("\n" <> ("-" |> String.duplicate(70)))
IO.puts("Step 6: Generating text with KV cache (#{max_new_tokens - 1} more tokens)")
IO.puts("-" |> String.duplicate(70))

# Prepare decode inputs function
prepare_decode_inputs = fn token_id, caches, position ->
  token_tensor = Nx.tensor([[token_id]], type: :s32)

  # Get RoPE embeddings for this specific position
  {full_cos, full_sin} = compute_rope_embeddings.(position + 1)
  # Slice out just the position we need (the last one)
  rope_cos_pos = Nx.slice(full_cos, [position, 0], [1, head_dim])
  rope_sin_pos = Nx.slice(full_sin, [position, 0], [1, head_dim])

  for gpu <- 0..(tp_size - 1) do
    layer_params_for_gpu = Enum.flat_map(layer_params, fn layer ->
      [
        layer.sa_norm, layer.ffn_norm,
        Enum.at(layer.q_shards, gpu), Enum.at(layer.k_shards, gpu),
        Enum.at(layer.v_shards, gpu), Enum.at(layer.o_shards, gpu),
        Enum.at(layer.gate_shards, gpu), Enum.at(layer.up_shards, gpu),
        Enum.at(layer.down_shards, gpu)
      ]
    end)

    [token_tensor, embed_tokens, final_norm_weight, lm_head_kernel, rope_cos_pos, rope_sin_pos] ++ layer_params_for_gpu ++ caches
  end
end

# Generate tokens with decode phase
generated_tokens = [next_token]
current_caches = kv_caches
current_cache_len = prompt_length

IO.write("  Generated text: #{Bumblebee.Tokenizer.decode(tokenizer, [next_token])}")

Enum.reduce(1..(max_new_tokens - 1), {generated_tokens, current_caches, current_cache_len}, fn i, {tokens, caches, cache_len} ->
  # Build decode SPMD for current cache length
  decode_spmd = build_decode_spmd.(1, cache_len)

  # Prepare inputs with last generated token
  # Position is cache_len (the position of the new token being generated)
  last_token = List.last(tokens)
  replica_inputs = prepare_decode_inputs.(last_token, caches, cache_len)

  # Run decode
  [[new_logits | new_caches] | _] = EXLA.SPMD.run(decode_spmd, replica_inputs)

  # Sample next token
  new_token = Nx.argmax(new_logits, axis: 1) |> Nx.to_flat_list() |> hd()

  # Print token
  IO.write(Bumblebee.Tokenizer.decode(tokenizer, [new_token]))

  # Progress indicator every 5 tokens
  if rem(i, 5) == 0 do
    IO.write(" [#{i}/#{max_new_tokens - 1}]")
  end

  # Return updated state
  {tokens ++ [new_token], new_caches, cache_len + 1}
end)

IO.puts("")

# ----------------------------------------------------------
# Summary
# ----------------------------------------------------------
IO.puts("\n" <> ("=" |> String.duplicate(70)))
IO.puts("Summary")
IO.puts("=" |> String.duplicate(70))

full_tokens = Nx.to_flat_list(input_ids) ++ generated_tokens
full_text = Bumblebee.Tokenizer.decode(tokenizer, full_tokens)

IO.puts("""

âœ“ COMPLETE - Proper Operations with Full Generation + RoPE!

Implemented:
  - PROPER embedding lookup via Value.gather
  - PROPER RMSNorm via Value.reduce
  - PROPER softmax attention via Value.reduce
  - PROPER causal masking via Value.iota
  - PROPER Rotary Position Embeddings (RoPE)
  - Full autoregressive generation with KV cache

Prompt: "#{prompt}"

Full Generated Text:
#{full_text}

Performance:
  - Prefill: #{Float.round(time_us / 1000, 2)} ms for #{prompt_length} tokens
  - Decode: #{max_new_tokens} tokens generated with O(1) computation per token

Model: Mistral 7B (#{num_layers} layers)
TP Configuration: #{tp_size} GPUs
Cache shape per layer: [1, #{local_kv_heads}, seq_len, #{head_dim}]

This demonstrates production-quality tensor parallel inference in Elixir!
""")
